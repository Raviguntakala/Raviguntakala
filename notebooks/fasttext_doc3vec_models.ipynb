{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884bab71-9b06-4ead-a357-ce16366acad2",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6851d1b-9676-4202-a9f5-83f3038a9902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4b643b-466d-48d1-8279-4bd1c6642e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 20:42:19,052 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2023-10-31 20:42:19,053 : INFO : built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\n",
      "2023-10-31 20:42:19,054 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\", 'datetime': '2023-10-31T20:42:19.054629', 'gensim': '4.3.2', 'python': '3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]', 'platform': 'Linux-5.10.0-26-cloud-amd64-x86_64-with-glibc2.31', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import modin.pandas as mpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "import gcsfs\n",
    "import mapply\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "import itertools\n",
    "import pickle\n",
    "client = bigquery.Client()\n",
    "\n",
    "from gensim import corpora\n",
    "from smart_open import smart_open\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from gensim.models import TfidfModel, OkapiBM25Model\n",
    "\n",
    "from gensim.similarities import Similarity\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "from gensim.models import fasttext\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39a8ff5-fe56-43b7-8969-a37880706e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapply.init(\n",
    "    n_workers=-1,\n",
    "    chunk_size=10000,\n",
    "    max_chunks_per_worker=0,\n",
    "    progressbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637e6b3-3bba-49df-92e9-524f937db187",
   "metadata": {},
   "source": [
    "### Tables used: \n",
    "<ol>\n",
    "    <li> `wmt-dca-catalog-dq-dev.SC_Final_Tables.IIS_CORE` - CORE TABLE SEE TABLE DIRECTORY </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abce031c-64e2-494e-8be6-86f2fec855ae",
   "metadata": {},
   "source": [
    "### Attributes Summary:\n",
    "#### Target Attribute \n",
    "- ELECTRONIC_WASTE_IND\n",
    "#### Standard Attributes\n",
    "- WPID\n",
    "- GTIN\n",
    "- PROD_TYPE_NM\n",
    "- PROD_NM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc61113-6ec4-4113-9584-aac7e92f91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT WPID,PROD_TYPE_NM FROM wmt-dca-catalog-dq-dev.SC_Final_Tables.IIS_CORE\n",
    "\"\"\"\n",
    "all_items = client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ac8de-1f17-4898-bc16-3ccd72a2f175",
   "metadata": {},
   "source": [
    "### Analysis: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eec998-f5bb-40f1-bd65-ea0270f5a5ca",
   "metadata": {},
   "source": [
    "##### Create a sample of books & t-shirt. Also create with a sample not containing either books or t-shirts & concatenate them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb17f957-adf8-4475-bbe8-5a35258ec60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_sample = all_items.groupby('PROD_TYPE_NM').sample(frac=.2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90843f21-5ff8-4b61-a36e-2dbba0139e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_sample_most = items_sample[~items_sample.PROD_TYPE_NM.isin(['Books','T-Shirts'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6d4d44c-1ffc-4351-ba00-db40865ecf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_sample_books = items_sample[items_sample.PROD_TYPE_NM.isin(['Books'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d23dc34-8537-4c8d-91d5-e15c1819d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_sample_ts = items_sample[items_sample.PROD_TYPE_NM.isin(['T-Shirts'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d08466a-8269-4784-b1f4-69aab17e23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_sample_books = items_sample_books.sample(frac=.5).reset_index(drop=True)\n",
    "items_sample_ts = items_sample_ts.sample(frac=.5).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8cc4786-661a-4632-90a3-6c9dfbef28ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Ray execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    import ray\n",
      "    ray.init()\n",
      "\n",
      "2023-10-27 19:44:42,624\tINFO worker.py:1642 -- Started a local Ray instance.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "2023-10-27 19:44:44,638 : INFO : Using sequential splitting in '.from_pandas()' because of some of the conditions are False: enough_elements=True; all_numeric_types=False; async_mode_on=False\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "2023-10-27 19:44:46,836 : INFO : Using sequential splitting in '.from_pandas()' because of some of the conditions are False: enough_elements=False; all_numeric_types=False; async_mode_on=False\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "2023-10-27 19:44:47,369 : INFO : Using sequential splitting in '.from_pandas()' because of some of the conditions are False: enough_elements=False; all_numeric_types=False; async_mode_on=False\n"
     ]
    }
   ],
   "source": [
    "items_sample = pd.concat([items_sample_most,items_sample_books,items_sample_ts],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10a08d18-f5f9-4931-bdd8-96902c1daca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4185745, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115b3d4-1340-4919-ab25-7071fd9bdd8c",
   "metadata": {},
   "source": [
    "##### Create a table  storing the above sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "000af918-8c51-4001-83e2-093368746871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `DataFrame.to_gbq` is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "Please refer to https://modin.readthedocs.io/en/stable/supported_apis/defaulting_to_pandas.html for explanation.\n",
      "4185745 out of 4185745 rows loaded.s]2023-10-27 19:45:23,373 : INFO : \n",
      "100%|██████████| 1/1 [00:00<00:00, 932.07it/s]\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "2023-10-27 19:45:23,375 : INFO : Using sequential splitting in '.from_pandas()' because of some of the conditions are False: enough_elements=True; all_numeric_types=False; async_mode_on=False\n"
     ]
    }
   ],
   "source": [
    "items_sample.to_gbq(project_id = \"wmt-dca-catalog-dq-dev\", destination_table = \"wmt-dca-catalog-dq-dev.SC_Final_Tables.ALL_ITEMS_RAND_SAMPLE20\", if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad53ba4-6f54-468c-96c7-61dbf66d1751",
   "metadata": {},
   "source": [
    "##### Create parquet files from the table created above and import data from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93114388-0984-42e9-908a-08598fbc5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = f\"\"\"\n",
    "        EXPORT DATA\n",
    "          OPTIONS (\n",
    "            uri = 'gs://phase2_scoreclean/pod1/word_counts/ALL_ITEMS_SAMPLE20/*.parquet',\n",
    "            format = 'parquet')\n",
    "        AS (SELECT A.WPID,PROD_TYPE_NM,WORDS_CLEAN_LINE FROM `wmt-dca-catalog-dq-dev.SC_Final_Tables.ALL_ITEMS_RAND_SAMPLE20` AS A\n",
    "        LEFT JOIN \n",
    "        (SELECT WPID,WORDS_CLEAN_LINE FROM wmt-dca-catalog-dq-dev.SC_Final_Tables.PROD_FULL_TEXT) AS B\n",
    "        ON A.WPID=B.WPID)\n",
    "        \"\"\"\n",
    "        job = client.query(QUERY)\n",
    "        while job.done()!=True:\n",
    "            print('waiting for bigquery')\n",
    "            time.sleep(3)\n",
    "        print('errors:',job.errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de4b5c5-6a0c-4a18-af92-1a6af1b9cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sample = dd.read_parquet('gs://phase2_scoreclean/pod1/word_counts/ALL_ITEMS_SAMPLE20/*.parquet')\n",
    "item_sample = item_sample.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f223bc6-073a-443f-aba2-b72abc13fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sample = item_sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec4759ad-2f73-4731-a102-c34ffea11fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'official creality ender max neo printer upgraded with cr touch auto leveling dual z-axis all-metal bowden extruder color knob screen large print size in cr touch auto bed leveling the cr touch intelligent leveling system can automatically compensate the printing height at different points of the printing platform the technology effectively improves the leveling accuracy mm and printing success rate power loss recovery and filament sensor the creality printers features the function of detecting filament runout or breakage power loss and resume printing after recovery by accurately recording the printing data at the time of power outage filament runout or breakage it helps to avoid the waste of filaments and time caused by accidents high-precision dual z-axis higher printing precision with z-axis dual-screw z-axis dual-motor design works smoother and more synchronously to lower the possibility of lines and ridges on the sides of your print thus improving the printing quality simple quick assembling of the printer body is pre-installed making assemblingextremely convenient with only steps and the maintenanceof the printer is simple and easy specification molding nbsp technology fdm nbsp extruder bowden extruder nbsp build volume mm nbsp extruder material full-metal nbsp machine dimension mm nbsp leveling mode cr touch auto-leveling nbsp package dimension mm nbsp display color knob screen nbsp net weight kg mainboard bit silent mainboard nbsp gross weight kg nbsp resume printing yes nbsp printing speed mm nbsp filament sensor yes nbsp printing precison mm nbsp rated voltage 120v 240v hz nbsp layer height mm nbsp rated power nbsp filament diameter mm nbsp data transmission method micro ub card nbsp nozzle quantity nbsp file format stl obj amf nozle diameter mm supported filament pla abs petg wood nbsp nozzle temperature up to nbsp supported language chinese english nbsp heat bed temperature up to nbsp slicing software creality slicer cura repetier-host simplify build surface carborundum class'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_sample['WORDS_CLEAN_LINE'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1476a072-3477-40cb-8ca1-5c0938bae5bd",
   "metadata": {},
   "source": [
    "##### Fetch and write the words in the product_typ_nm  for each product in a .txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d3bf3f-f348-49f7-83ad-ad6936801735",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sample_list=item_sample['WORDS_CLEAN_LINE'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b611059d-6fdb-4134-85ce-28a6c89baa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4185745/4185745 [00:11<00:00, 378963.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('item_sample_20_final.txt', 'w') as fp:\n",
    "    for item in tqdm(item_sample_list):\n",
    "        # write each item on a new line\n",
    "        fp.write(item + \"\\n\")\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ad2d3-ad5f-4b97-b7bc-bfa3904a6eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca92e17-8cfb-4f03-acad-2e6ab5d3bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://item_sample_20_final.txt [Content-Type=text/plain]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "- [1 files][  4.7 GiB/  4.7 GiB]   89.2 MiB/s                                   \n",
      "Operation completed over 1 objects/4.7 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp item_sample_20.txt gs://phase2_scoreclean/pod1/word_counts/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef9e316-efe8-4961-955d-3bcde836ad15",
   "metadata": {},
   "source": [
    "##### Create a dictionary of words from the text file saved above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e6f689b-1354-490b-9a1a-66bc4d5f20aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2507496it [08:21, 4997.78it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(line.split() for line in tqdm(open('item_sample.txt', encoding='utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcc4d102-8a66-4b60-9485-bbe19cfa767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 01:54:23,589 : INFO : loading Dictionary object from models/item_sample_20_final_dictionary\n",
      "2023-10-31 01:54:24,862 : INFO : Dictionary lifecycle event {'fname': 'models/item_sample_20_final_dictionary', 'datetime': '2023-10-31T01:54:24.862800', 'gensim': '4.3.2', 'python': '3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]', 'platform': 'Linux-5.10.0-26-cloud-amd64-x86_64-with-glibc2.31', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary.load('models/item_sample_20_final_dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a4d49a1-bf41-4f73-bed0-a29b2a8a18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_model = OkapiBM25Model(dictionary=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e8dd325-40fc-422d-8629-4aa6a6a84b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 01:52:14,425 : INFO : loading OkapiBM25Model object from models/bm25.model\n",
      "2023-10-31 01:52:14,781 : INFO : OkapiBM25Model lifecycle event {'fname': 'models/bm25.model', 'datetime': '2023-10-31T01:52:14.781005', 'gensim': '4.3.2', 'python': '3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]', 'platform': 'Linux-5.10.0-26-cloud-amd64-x86_64-with-glibc2.31', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "document_model = OkapiBM25Model.load('models/bm25.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842fa2f3-30b6-4975-9f19-fd8a3a5280fb",
   "metadata": {},
   "source": [
    "##### Create a corpus of words from the txt file created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f6bacc6-4456-4ae9-8ee7-3148630c5fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "        for line in tqdm(open('item_sample.txt', encoding='utf-8')):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield dictionary.doc2bow(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20a0393a-3302-4aae-a1d5-e57f7cb556b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=MyCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cee0bf3-d603-40a2-a5b5-285120f8a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_corpus = document_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c408f46e-b9b1-4897-a893-a1768f2f74a2",
   "metadata": {},
   "source": [
    "##### Create an index which is used to generate the 'elec_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94ac7d70-f52d-400b-8d08-85ca5b6e59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tmpfile = get_tmpfile(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bef76e4-64aa-4836-a28a-353645226547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169983it [01:51, 2026.57it/s]2023-10-31 02:01:04,620 : INFO : PROGRESS: fresh_shard size=20000\n",
      "173972it [01:53, 1534.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mSimilarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_tmpfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbm25_corpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mshardsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/similarities/docsim.py:356\u001b[0m, in \u001b[0;36mSimilarity.__init__\u001b[0;34m(self, output_prefix, corpus, num_features, num_best, chunksize, shardsize, norm)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh_docs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh_nnz \u001b[38;5;241m=\u001b[39m [], \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/similarities/docsim.py:400\u001b[0m, in \u001b[0;36mSimilarity.add_documents\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshards \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshards[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m<\u001b[39m min_ratio \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshardsize:\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;66;03m# The last shard was incomplete (<; load it back and add the documents there, don't start a new shard\u001b[39;00m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreopen_shard()\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m corpus:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc, numpy\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    402\u001b[0m         doclen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(doc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/interfaces.py:177\u001b[0m, in \u001b[0;36mTransformedCorpus.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m transformed\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[doc]\n",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m, in \u001b[0;36mMyCorpus.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_sample.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;66;03m# assume there's one document per line, tokens separated by whitespace\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mdictionary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc2bow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/corpora/dictionary.py:246\u001b[0m, in \u001b[0;36mDictionary.doc2bow\u001b[0;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[1;32m    244\u001b[0m counter \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m document:\n\u001b[0;32m--> 246\u001b[0m     counter[w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    248\u001b[0m token2id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken2id\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_update \u001b[38;5;129;01mor\u001b[39;00m return_missing:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "index = Similarity(index_tmpfile, bm25_corpus, num_features=len(dictionary),chunksize=256,shardsize=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd37d490-a929-423e-bd62-181c252950f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = dictionary.doc2bow('''\n",
    "'''.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c24976cb-ae7d-4c19-84ae-1cb8ee87872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_sample['elec_score'] = index[query]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c15ac5c-e246-40c9-88f8-9838d37699c9",
   "metadata": {},
   "source": [
    "##### Storing the 'elec_score' in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e1cc5cd-b004-48a0-9807-235051f75d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_sample[books_sample['elec_score']!=0].sort_values('elec_score',ascending=False).to_csv('elec_score.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1082dbf-391d-4a22-85a3-4840de9214fa",
   "metadata": {},
   "source": [
    "##### Training & saving the Fast Text model with  text file created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc677569-44b3-4d31-9d9a-3968ec762f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = FastText(\n",
    "    sg=1, # use skip-gram: usually gives better results\n",
    "    vector_size=100, # embedding dimension (default)\n",
    "    window=10, # window size: 10 tokens before and 10 tokens after to get wider context\n",
    "    min_count=5, # only consider tokens with at least n occurrences in the corpus\n",
    "    negative=15, # negative subsampling: bigger than default to sample negative examples more\n",
    "    min_n=2, # min character n-gram\n",
    "    max_n=5, # max character n-gram\n",
    "    workers=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16866d58-9f05-45b0-9477-2e9698a4494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.build_vocab(corpus_file='item_sample_20_final.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586d539-d79f-4771-b107-65abf06a1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.train(\n",
    "    corpus_file='item_sample_20_final.txt',\n",
    "    epochs=6,\n",
    "    total_examples=ft_model.corpus_count, \n",
    "    total_words=ft_model.corpus_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2d3ba-a0ca-41ea-ab4d-56dfd806bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save('_fasttext20_final.model') #save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7ff76-45fc-4239-a4fa-245864740a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b5eea0-109a-4fb8-be40-84e9bb62abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_model = Doc2Vec(\n",
    "    vector_size=100, # embedding dimension (default)\n",
    "    window=10, # window size: 10 tokens before and 10 tokens after to get wider context\n",
    "    min_count=5, # only consider tokens with at least n occurrences in the corpus\n",
    "    negative=15, # negative subsampling: bigger than default to sample negative examples more\n",
    "    workers=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b20b5-a7cf-4bab-bf15-568dcf215bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_model.build_vocab(corpus_file='item_sample_20_final.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee19fc9-044d-4754-8981-181042590f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_model.train(\n",
    "    corpus_file='item_sample_20_final.txt',\n",
    "    epochs=10,\n",
    "    total_examples=dv_model.corpus_count, \n",
    "    total_words=dv_model.corpus_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454b0e6-90fe-4c33-9c36-4f1d8b838665",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_model.save('_doc2vec20_final.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85130d2b-a0be-4785-b8d8-1f0cebf09a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1024e1ba-3559-40d2-903b-5842c28f93d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://phase2_scoreclean/pod1/word_counts/models/_doc2vec20_final.model...\n",
      "Copying gs://phase2_scoreclean/pod1/word_counts/models/_doc2vec20_final.model.dv.vectors.npy...\n",
      "Copying gs://phase2_scoreclean/pod1/word_counts/models/_doc2vec20_final.model.syn1neg.npy...\n",
      "Copying gs://phase2_scoreclean/pod1/word_counts/models/_doc2vec20_final.model.wv.vectors.npy...\n",
      "- [4 files][  2.0 GiB/  2.0 GiB]  102.0 MiB/s                                   \n",
      "Operation completed over 4 objects/2.0 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://phase2_scoreclean/pod1/word_counts/models/_doc2vec20_final* models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f199f-07c5-46d5-acb9-f74fe4cc5b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
