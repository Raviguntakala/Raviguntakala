{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66839094",
   "metadata": {},
   "source": [
    "## IMAGE AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34629ab2",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2300c12-6225-4a70-a4d1-53d8f2ebb211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 12:05:19.740133: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-11 12:05:24.028038: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-10-11 12:05:24.029500: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-10-11 12:05:24.029514: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415ca91",
   "metadata": {},
   "source": [
    "#### Initial Data Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e9ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of data selection for dataset creation\n",
    "query = \"\"\"\n",
    "            SELECT * FROM wmt-dca-catalog-dq-dev.POD2.Triage_Analysis where PROD_TYPE_NM IN ('Hair Sprays')\n",
    "        \"\"\"\n",
    "product_data = client.query(query).to_dataframe()\n",
    "product_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be570cfa",
   "metadata": {},
   "source": [
    "#### Download Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c450978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(image_url, filename, directory):\n",
    "    \n",
    "    \"\"\"\n",
    "    function to down images for a given url and save to specified directory\n",
    "    \n",
    "    Parameters:\n",
    "    - image_url (str): The Main image url.\n",
    "    - filename (str): The download image name.\n",
    "    - directory (str): The directory to save the  images.\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        #print(f\"Image already exists: {filename}\")\n",
    "        return\n",
    "\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(filepath, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        #print(f\"Image saved: {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download image: {image_url}\")\n",
    "\n",
    "def save_images(df, url_column, filename_column, directory, num_threads=10):\n",
    "    image_urls = df[url_column]\n",
    "    filenames = df[filename_column] + '.jpeg'\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        for image_url, filename in zip(image_urls, filenames):\n",
    "            executor.submit(download_image, image_url, filename, directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e92e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(product_data,\"MAINIMAGEURL\",\"WPID\",\"/train_images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a3507e",
   "metadata": {},
   "source": [
    "#### Augment downloaded Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae1714d8-4992-43c8-84ea-3dad540262ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augment (img, output_directory):\n",
    "    \"\"\"\n",
    "    Augments train images from the input directory and saves them to the specified output directory.\n",
    "\n",
    "    Parameters:\n",
    "    - img (str): The original train images.\n",
    "    - output_directory (str): The directory to save the augmented images.\n",
    "    \n",
    "    \"\"\"\n",
    "    # get image name which is a product id\n",
    "    product_id = img.split(\".\")[0]\n",
    "    \n",
    "    #load the image\n",
    "    img = load_img(f'./train_images/{img}')\n",
    "    \n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    #save original image\n",
    "    img.save(f'{output_directory}/{product_id}_original.jpeg')\n",
    "    \n",
    "    # Saturation effect\n",
    "    saturated = tf.image.adjust_saturation(img, saturation_factor = 1.5, name=None)\n",
    "    img_sat = array_to_img(saturated)\n",
    "    img_sat.save(f'{output_directory}/{product_id}_saturated.jpeg')\n",
    "    \n",
    "    # Flipped right to left\n",
    "    flipped = tf.image.flip_left_right(img)\n",
    "    img_flipped = array_to_img(flipped)\n",
    "    img_flipped.save(f'{output_directory}/{product_id}_flipped.jpeg')\n",
    "    \n",
    "    # Contrast effect\n",
    "    contrast = tf.image.adjust_contrast(img,contrast_factor = 3.)\n",
    "    img_constrasted = array_to_img(contrast)\n",
    "    img_constrasted.save(f'{output_directory}/{product_id}_constrast.jpeg')\n",
    "    \n",
    "    # Brightness effect\n",
    "    brightness = tf.image.adjust_brightness(img, delta=0.1)\n",
    "    img_brightned = array_to_img(brightness)\n",
    "    img_brightned.save(f'{output_directory}/{product_id}_brightness.jpeg')\n",
    "    \n",
    "    # Traslation - shift x-axis and y-axis\n",
    "    image_2_arr = np.array(img)\n",
    "    datagen = ImageDataGenerator(\n",
    "              width_shift_range=-0.2,  # shift horizontally by 20%\n",
    "              height_shift_range=-0.2, # shift vertically by 20%\n",
    "            )\n",
    "    img_translated = datagen.apply_transform(image_2_arr, {'tx': 50, 'ty': 50})\n",
    "    img_translated = array_to_img(img_translated)\n",
    "    img_translated.save(f'{output_directory}/{product_id}_translated.jpeg')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297f3a4e-e978-4e32-a4cb-80c1960f2c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image files\n",
    "image_files = [img for img in os.listdir(\"./train_images/\") if img.split(\".\")[1] in ['jpeg']]\n",
    "len(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec55406c-f420-4bfd-a66a-fdf1e6c84a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 12:05:48.570669: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-10-11 12:05:48.571575: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-10-11 12:05:48.571603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (prarja): /proc/driver/nvidia/version does not exist\n",
      "2023-10-11 12:05:48.577434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for file in image_files:\n",
    "    image_augment (file,'./train_augmented_images/')\n",
    "    count = count + 1\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a466416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying augmented images into GCP bucket\n",
    "!gsutil -m cp ./train_augmented_images/*.jpeg gs://<INSERT YOUR DATASET>/Accuracy_Image_Classification/hairspray/train_augmented_images/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07540a28",
   "metadata": {},
   "source": [
    "#### Create a CSV file for train model dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37be4ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GCS urls for train images and map them to their class by WPID to Is Aerosol column\n",
    "\n",
    "label_df = pd.DataFrame()\n",
    "\n",
    "url_string_to_add = \"gs://<INSERT YOUR DATASET>/Accuracy_Image_Classification/hairspray/train_augmented_images/\"\n",
    "\n",
    "urls_for_gcs, classes = [], []\n",
    "\n",
    "image_files = [img for img in os.listdir(\"./train_augmented_images/\") if img.split(\".\")[1] in ['jpeg']]\n",
    "\n",
    "for file in image_files:\n",
    "    urls_for_gcs.append(url_string_to_add + file)\n",
    "    classes.append(df['AEROSOL_IND'][df['WPID'] == f'{file.split(\"_\")[0]}'].values[0])\n",
    "\n",
    "label_df['gcs_url'] = urls_for_gcs\n",
    "label_df['class'] = classes\n",
    "\n",
    "\n",
    "label_df.to_csv(\"./csv_files/hairspray_train_images_uri.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e425ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying augmented images uri dataset into GCP bucket\n",
    "!gsutil cp ./csv_files/hairspray_train_images_uri.csv gs://<INSERT YOUR DATASET>/Accuracy_Image_Classification/hairspray/training_dataset/"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m111"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
