{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470b25fb",
   "metadata": {},
   "source": [
    "## Generation and training of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c8bcb1",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd47343-d3c8-452f-837d-3fa0eb5cab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 11:41:25.968233: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-26 11:41:27.331530: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-10-26 11:41:27.331670: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-10-26 11:41:27.331681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "from google.cloud import storage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb81a20-f931-4bd8-a04a-d60dd12b9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training dataset path\n",
    "IMPORT_FILE='gs://<INSERT YOUR DATASET>/Accuracy_Image_Classification/hairspray/training_dataset/<INSERT DATASET NAME>.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf183ace",
   "metadata": {},
   "source": [
    "### Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e880cc8-d6d3-41a1-92a7-735e5db2620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/410747957313/locations/us-central1/datasets/1104306597984731136\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = aiplatform.ImageDataset.create(\n",
    "    display_name=\"<INSERT DATASET DISPLAY NAME>\",\n",
    "    gcs_source=[IMPORT_FILE],\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.image.single_label_classification,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af8f24",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0a8b3e-6fc6-4bb0-a0c6-2829bade53ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.cloud.aiplatform.training_jobs.AutoMLImageTrainingJob object at 0x7f72ff2bbb20>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dag = aiplatform.AutoMLImageTrainingJob(\n",
    "    display_name=\"<INSERT MODEL DISPLAY NAME>\", #model display name\n",
    "    prediction_type=\"classification\",\n",
    "    multi_label=False,\n",
    "    model_type=\"CLOUD\",\n",
    "    base_model=None,\n",
    ")\n",
    "\n",
    "print(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3409123",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b0336-fe53-4aee-85c1-378f33e36aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"<INSERT MODEL DISPLAY NAME>\",\n",
    "    training_fraction_split=0.98,\n",
    "    validation_fraction_split=0.01,\n",
    "    test_fraction_split=0.01,\n",
    "    budget_milli_node_hours=8000,\n",
    "    disable_early_stopping=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99207122-2e05-4f69-9ef9-2a0b643c46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"model training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d04cb2e-5abe-4ced-8610-673c026542e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m111"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
